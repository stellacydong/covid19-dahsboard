{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e7ec490",
   "metadata": {},
   "source": [
    "1) where the hotspots are currently and what areas to focus on next on a map.\n",
    "\n",
    "2) How would you calculate the fatality rate and what issues do you see with presenting those figures based on this dataset?\n",
    "\n",
    "3) Please cite any additional sources you used for research and reference any existing dashboards you used for inspiration\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb35c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d22cad",
   "metadata": {},
   "source": [
    "# load data \n",
    "\n",
    "rename some columns name, drop some un-necessary columns in order to merge the tables later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9db80e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = {'wc':'time_series_covid19_confirmed_global.csv',\\\n",
    "            'wd':'time_series_covid19_deaths_global.csv',\\\n",
    "            'uc':'time_series_covid19_confirmed_US.csv',\\\n",
    "            'ud':'time_series_covid19_deaths_US.csv',\\\n",
    "            'geo':'UID_ISO_FIPS_LookUp_Table.csv'}\n",
    "\n",
    "target_path = {'summary':'time_series_covid19.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd841138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read global data\n",
    "wc = pd.read_csv(\"csse_covid_19_time_series/\"+src_path['wc'])\n",
    "wd = pd.read_csv(\"csse_covid_19_time_series/\"+src_path['wd'])\n",
    "\n",
    "# Geographical information will be merged\n",
    "wc.drop(['Lat','Long'],axis=1,inplace=True)\n",
    "wd.drop(['Lat','Long'],axis=1,inplace=True)\n",
    "\n",
    "# Read US data\n",
    "uc = pd.read_csv(\"csse_covid_19_time_series/\"+src_path['uc'])\n",
    "ud = pd.read_csv(\"csse_covid_19_time_series/\"+src_path['ud'])\n",
    "\n",
    "# rename some columns name so that all the tables have the same names \n",
    "uc.rename(columns={'Province_State':'Province/State','Country_Region':'Country/Region','Long_':'Long'},inplace=True)\n",
    "ud.rename(columns={'Province_State':'Province/State','Country_Region':'Country/Region','Long_':'Long'},inplace=True)\n",
    "\n",
    "# County-level data to be purged\n",
    "uc.drop(['UID','iso2','code3','Admin2','FIPS','Combined_Key'],axis=1,inplace=True)\n",
    "ud.drop(['UID','iso2','code3','Admin2','FIPS','Combined_Key'],axis=1,inplace=True)\n",
    "\n",
    "# Append Population column to infections data\n",
    "uc = pd.concat([uc.iloc[:,:5],ud['Population'],uc.iloc[:,5:]],axis=1)\n",
    "\n",
    "# Read geographical information\n",
    "geo = pd.read_csv(src_path['geo'])\n",
    "geo.rename(columns={'Province_State':'Province/State','Country_Region':'Country/Region','Long_':'Long'},inplace=True)\n",
    "geo.drop(['UID','iso2','code3','Admin2','FIPS','Combined_Key'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8697e510",
   "metadata": {},
   "source": [
    "# clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5ae42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the columns of each table into same order \n",
    "def reorder_columns(cols):\n",
    "    # iso\n",
    "    # Province/State\n",
    "    # Country/Region\n",
    "    # Lat\n",
    "    # Long\n",
    "    # Population\n",
    "    lst = cols\n",
    "    bases_idx = [cols.get_loc('iso3'),cols.get_loc('Province/State'),cols.get_loc('Country/Region'),cols.get_loc('Lat'),cols.get_loc('Long'),cols.get_loc('Population')]\n",
    "    bases = cols[bases_idx]\n",
    "\n",
    "    return list(bases) + list(lst.drop(bases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16cad567",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff=815  # cutoff = number of days frmo 4/7/22 \n",
    "\n",
    "# Get least recent date (reporting time gaps)\n",
    "min_latest = datetime.strptime(min(wc.columns[-1],wd.columns[-1],uc.columns[-1],ud.columns[-1]),'%m/%d/%y')\n",
    "max_first = datetime.strptime(max(wc.columns[2],wd.columns[2],uc.columns[6],ud.columns[6]),'%m/%d/%y')\n",
    "min_date = max(min_latest-timedelta(days=cutoff),max_first)\n",
    "\n",
    "start_date = min_date.strftime('%-m/%-d/%y')\n",
    "end_date = min_latest.strftime('%-m/%-d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97499cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/22/20\n",
      "4/7/22\n"
     ]
    }
   ],
   "source": [
    "print(start_date)\n",
    "print(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92eb20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = {'wc':list(wc.columns[:2]) \\\n",
    "            +list(wc.columns[wc.columns.get_loc(start_date):wc.columns.get_loc(end_date)+1]),\n",
    "            'wd':list(wd.columns[:2])\\\n",
    "            +list(wd.columns[wd.columns.get_loc(start_date):wc.columns.get_loc(end_date)+1]),\\\n",
    "            'uc':list(uc.columns[:6])\\\n",
    "            +list(uc.columns[uc.columns.get_loc(start_date):uc.columns.get_loc(end_date)+1]),\\\n",
    "            'ud':list(ud.columns[:6])\\\n",
    "            +list(ud.columns[ud.columns.get_loc(start_date):ud.columns.get_loc(end_date)+1])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "60f01a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = wc[col_list['wc']].merge(geo,on=['Country/Region','Province/State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c260f5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>1/28/20</th>\n",
       "      <th>1/29/20</th>\n",
       "      <th>...</th>\n",
       "      <th>4/2/22</th>\n",
       "      <th>4/3/22</th>\n",
       "      <th>4/4/22</th>\n",
       "      <th>4/5/22</th>\n",
       "      <th>4/6/22</th>\n",
       "      <th>4/7/22</th>\n",
       "      <th>iso3</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Diamond Princess</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MS Zaandam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer Olympics 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.6491</td>\n",
       "      <td>139.7737</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>80150811</td>\n",
       "      <td>80155397</td>\n",
       "      <td>80179289</td>\n",
       "      <td>80208810</td>\n",
       "      <td>80248986</td>\n",
       "      <td>80289237</td>\n",
       "      <td>USA</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>329466283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter Olympics 2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.9042</td>\n",
       "      <td>116.4074</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 813 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Province/State        Country/Region  1/22/20  1/23/20  1/24/20  1/25/20  \\\n",
       "105            NaN      Diamond Princess        0        0        0        0   \n",
       "173            NaN            MS Zaandam        0        0        0        0   \n",
       "240            NaN  Summer Olympics 2020        0        0        0        0   \n",
       "255            NaN                    US        1        1        2        2   \n",
       "279            NaN  Winter Olympics 2022        0        0        0        0   \n",
       "\n",
       "     1/26/20  1/27/20  1/28/20  1/29/20  ...    4/2/22    4/3/22    4/4/22  \\\n",
       "105        0        0        0        0  ...       712       712       712   \n",
       "173        0        0        0        0  ...         9         9         9   \n",
       "240        0        0        0        0  ...       865       865       865   \n",
       "255        5        5        5        6  ...  80150811  80155397  80179289   \n",
       "279        0        0        0        0  ...       535       535       535   \n",
       "\n",
       "       4/5/22    4/6/22    4/7/22  iso3      Lat      Long   Population  \n",
       "105       712       712       712   NaN      NaN       NaN          NaN  \n",
       "173         9         9         9   NaN      NaN       NaN          NaN  \n",
       "240       865       865       865   NaN  35.6491  139.7737          NaN  \n",
       "255  80208810  80248986  80289237   USA  40.0000 -100.0000  329466283.0  \n",
       "279       535       535       535   NaN  39.9042  116.4074          NaN  \n",
       "\n",
       "[5 rows x 813 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc[((wc['Lat']==0) & (wc['Long']==0) & (wc['Province/State'] != 'Unknown')) \\\n",
    "           | (wc['iso3'].isin(['USA'])) | (wc['iso3'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fcd3b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows above and reorder the columns \n",
    "wc.drop(wc[((wc['Lat']==0) & (wc['Long']==0) & (wc['Province/State'] != 'Unknown')) \\\n",
    "           | (wc['iso3'].isin(['USA'])) | (wc['iso3'].isnull())].index,inplace=True)\n",
    "wc = wc[reorder_columns(wc.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49ffcba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = wd[col_list['wd']].merge(geo,on=['Country/Region','Province/State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23e86b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>1/28/20</th>\n",
       "      <th>1/29/20</th>\n",
       "      <th>...</th>\n",
       "      <th>4/2/22</th>\n",
       "      <th>4/3/22</th>\n",
       "      <th>4/4/22</th>\n",
       "      <th>4/5/22</th>\n",
       "      <th>4/6/22</th>\n",
       "      <th>4/7/22</th>\n",
       "      <th>iso3</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Diamond Princess</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MS Zaandam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer Olympics 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.6491</td>\n",
       "      <td>139.7737</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>981612</td>\n",
       "      <td>981644</td>\n",
       "      <td>982099</td>\n",
       "      <td>982576</td>\n",
       "      <td>983817</td>\n",
       "      <td>984571</td>\n",
       "      <td>USA</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>329466283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter Olympics 2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.9042</td>\n",
       "      <td>116.4074</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 813 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Province/State        Country/Region  1/22/20  1/23/20  1/24/20  1/25/20  \\\n",
       "105            NaN      Diamond Princess        0        0        0        0   \n",
       "173            NaN            MS Zaandam        0        0        0        0   \n",
       "240            NaN  Summer Olympics 2020        0        0        0        0   \n",
       "255            NaN                    US        0        0        0        0   \n",
       "279            NaN  Winter Olympics 2022        0        0        0        0   \n",
       "\n",
       "     1/26/20  1/27/20  1/28/20  1/29/20  ...  4/2/22  4/3/22  4/4/22  4/5/22  \\\n",
       "105        0        0        0        0  ...      13      13      13      13   \n",
       "173        0        0        0        0  ...       2       2       2       2   \n",
       "240        0        0        0        0  ...       0       0       0       0   \n",
       "255        0        0        0        0  ...  981612  981644  982099  982576   \n",
       "279        0        0        0        0  ...       0       0       0       0   \n",
       "\n",
       "     4/6/22  4/7/22  iso3      Lat      Long   Population  \n",
       "105      13      13   NaN      NaN       NaN          NaN  \n",
       "173       2       2   NaN      NaN       NaN          NaN  \n",
       "240       0       0   NaN  35.6491  139.7737          NaN  \n",
       "255  983817  984571   USA  40.0000 -100.0000  329466283.0  \n",
       "279       0       0   NaN  39.9042  116.4074          NaN  \n",
       "\n",
       "[5 rows x 813 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd[((wd['Lat']==0) & (wd['Long']==0) & (wd['Province/State'] != 'Unknown')) \\\n",
    "           | (wd['iso3'].isin(['USA'])) | (wd['iso3'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee9104bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows above \n",
    "wd.drop(wd[((wd['Lat']==0) & (wd['Long']==0) & (wd['Province/State'] != 'Unknown')) \\\n",
    "           | (wd['iso3'].isin(['USA'])) | (wd['iso3'].isnull())].index,inplace=True)\n",
    "wd = wd[reorder_columns(wd.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ed26970",
   "metadata": {},
   "outputs": [],
   "source": [
    "uc = uc.loc[((uc['Lat']!=0) | (uc['Long']!=0)) & ((uc['iso3'].notnull())),col_list['uc']]\n",
    "\n",
    "# groupby the values by each state and generate 2 tables: one for sum, and the other for mean values \n",
    "us_geo = uc.groupby(['iso3','Country/Region','Province/State'])[['Lat','Long']].mean()\n",
    "uc_core = uc.groupby(['iso3','Country/Region','Province/State']).sum().drop(['Lat','Long'],axis=1)\n",
    "\n",
    "# merge the mean and sum tables \n",
    "uc = pd.merge(uc_core,us_geo,on=['iso3','Country/Region','Province/State']).reset_index()\n",
    "\n",
    "# reorder the columns \n",
    "uc = uc[reorder_columns(uc.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5db4908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ud = ud.loc[((ud['Lat']!=0) | (ud['Long']!=0)) & ((ud['iso3'].notnull())),col_list['ud']]\n",
    "\n",
    "# groupby the values by each state and generate 2 tables: one for sum, and the other for mean values \n",
    "ud_core = ud.groupby(['iso3','Country/Region','Province/State']).sum().drop(['Lat','Long'],axis=1)\n",
    "\n",
    "# merge the mean and sum tables \n",
    "ud = pd.merge(ud_core,us_geo,on=['iso3','Country/Region','Province/State']).reset_index()\n",
    "\n",
    "# reorder the columns \n",
    "ud = ud[reorder_columns(ud.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4054d8ef",
   "metadata": {},
   "source": [
    "## group both global and us data by type (confirmed or deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ac734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirmed and Deaths\n",
    "data = pd.concat([wc,uc])\n",
    "\n",
    "# # Population manipulation (No country-level statistics for multi-states)\n",
    "# base_pop = 1e5\n",
    "# data['num_states'] = data.groupby(['iso3','Country/Region']).iso3.transform('size')\n",
    "# data.loc[(data['Province/State'].isnull()) & (data['num_states']>1),'Population'] = 0\n",
    "# data.drop('num_states',axis=1,inplace=True)\n",
    "\n",
    "# # Wide to long form transformation\n",
    "# data = data.melt(id_vars=['iso3','Province/State','Country/Region','Lat','Long','Population'])\n",
    "# data.rename(columns={'variable':'Date','value':type},inplace=True)\n",
    "# # data['Date'] = pd.to_datetime(data['Date'],format='%m/%d/%y')\n",
    "# data[type].fillna(0,inplace=True)\n",
    "# data['Province/State'].replace(np.nan,'NA',inplace=True)\n",
    "\n",
    "# # Reorder columns\n",
    "# data = data[[data.columns[-2]]+list(data.columns[:-2])+[data.columns[-1]]]\n",
    "\n",
    "# # per 100K (r_: Rate)\n",
    "# data['r_'+type] = data[type]/data['Population']*base_pop\n",
    "\n",
    "# # Daily changes (i_: Daily Raw, ri_: Daily Rate)\n",
    "# data['i_'+type] = data[type]-data.groupby(['iso3','Province/State','Country/Region'])[type].shift(1)\n",
    "# data['i_'+type].fillna(data[type],inplace=True)\n",
    "# # print(data[['Date','Country/Region','Province/State',type,'i_'+type]])\n",
    "# # print(data)\n",
    "# data['ri_'+type] = data['i_'+type]/data['Population']*base_pop\n",
    "# # data['ri'+type].fillna(data['r'+type],inplace=True)\n",
    "\n",
    "# # Country-level grouping\n",
    "# data['Tot_'+type] = data.groupby(['Date','iso3','Country/Region'])[type].transform('sum')\n",
    "\n",
    "# data['iTot_'+type] = data.groupby(['Date','iso3','Country/Region'])['i_'+type].transform('sum')\n",
    "# data['rTot_'+type] = data['Tot_'+type]/data.groupby(['Date','iso3','Country/Region'])['Population'].transform('sum')*base_pop\n",
    "# data['riTot_'+type] = data['iTot_'+type]/data.groupby(['Date','iso3','Country/Region'])['Population'].transform('sum')*base_pop\n",
    "\n",
    "# # print(data[['Date','Country/Region','Province/State',type,'i_'+type]])\n",
    "\n",
    "# data.drop(data[data['Date']==data['Date'][0]].index,inplace=True)\n",
    "# data = data.round(4)\n",
    "# data.reset_index(drop=True,inplace=True)\n",
    "# #     print(data[['Date','Country/Region','Province/State',type,'i_'+type]])\n",
    "\n",
    "# #     print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f36cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c6443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d478bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and group datasets\n",
    "wc, wd, uc, ud = clean_data(wc, wd, uc, ud, geo)\n",
    "confirmed = group_by_type(wc,uc,'Confirmed')\n",
    "deaths = group_by_type(wd,ud,'Deaths')\n",
    "\n",
    "covid = confirmed.merge(deaths,on=['Date','iso3','Province/State','Country/Region','Lat','Long','Population'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58fa370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeeb2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(wc, wd, uc, ud, geo, \n",
    "    \n",
    "    \n",
    "\n",
    "#     ud.shape()\n",
    "    return wc, wd, uc, ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb1d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5237b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a921490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_appendfile():\n",
    "    # Read current file\n",
    "    file_list = target_path['summary']\n",
    "\n",
    "#     read_columns = ['Date','iso3','Province/State','Country/Region','Lat','Long',\\\n",
    "#                     'Population','Confirmed','r_Confirmed','i_Confirmed','ri_Confirmed',\\\n",
    "#                     'Tot_Confirmed','iTot_Confirmed','rTot_Confirmed','riTot_Confirmed',\\\n",
    "#                     'Deaths','r_Deaths','i_Deaths','ri_Deaths','Tot_Deaths','iTot_Deaths',\\\n",
    "#                     'rTot_Deaths','riTot_Deaths']\n",
    "\n",
    "#     try:\n",
    "#         print(\"Reading previous summary data with the filename: \"+file_list)\n",
    "#         last = pd.read_csv(\"data/\"+target_path['summary'])\n",
    "#         new = last.copy()\n",
    "#         if len(read_columns) == len(last.columns):\n",
    "#             status = 'Replace'\n",
    "#         else:\n",
    "#             status = \"New\"\n",
    "\n",
    "#     except FileNotFoundError:\n",
    "#         print('Current summary file not found\\nNo backup file(s) will be created')\n",
    "#         status = \"New\"\n",
    "\n",
    "\n",
    "    ds = read_source()\n",
    "    start_date = get_startdate(ds)\n",
    "    new = ds\n",
    "\n",
    "    # else:\n",
    "    #     # ds = read_source(start_date)\n",
    "    #     new.drop(new.loc[new['Date']>=start_date,:].index,inplace=True)\n",
    "\n",
    "    write_date = datetime.strptime(ds.iloc[-1]['Date'],'%m/%d/%y').strftime('%m-%d-%Y')\n",
    "\n",
    "    # Write to files\n",
    "#     print(\"Updating summary data: {}\".format(status))\n",
    "    write_file(new,'new',write_date)\n",
    "    print(\"Summary data successfully updated\")\n",
    "    \n",
    "#     if status == 'Replace':\n",
    "#         write_file(last,'last',write_date)\n",
    "#         write_file(new,'new',write_date)\n",
    "#         write_file(new,'remote',write_date)\n",
    "#     else:\n",
    "#         write_file(new,'new',write_date)\n",
    "#         write_file(new,'remote',write_date)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "234b729c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7df52a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_source(start_date=None):\n",
    "    \n",
    "    \n",
    "    # print(covid)\n",
    "\n",
    "    return covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9361cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_startdate(data,gaps=5):\n",
    "    # Get last date in the csv file \n",
    "    start_dt = datetime.strptime(max(data['Date']),'%m/%d/%y').date()\n",
    "    end_dt = date.today()\n",
    "    \n",
    "    print(start_dt)\n",
    "    print(end_dt)\n",
    "\n",
    "    if start_dt < end_dt-timedelta(days=1):\n",
    "        start_dt -= timedelta(days=gaps)\n",
    "    \n",
    "    # %- option only works for Unix-based systems\n",
    "    return start_dt.strftime('%-m/%-d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bd8158f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "107f8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_type(data_1, data_2, type):\n",
    "    # Confirmed and Deaths\n",
    "    data = pd.concat([data_1,data_2])\n",
    "\n",
    "    # Population manipulation (No country-level statistics for multi-states)\n",
    "    base_pop = 1e5\n",
    "    data['num_states'] = data.groupby(['iso3','Country/Region']).iso3.transform('size')\n",
    "    data.loc[(data['Province/State'].isnull()) & (data['num_states']>1),'Population'] = 0\n",
    "    data.drop('num_states',axis=1,inplace=True)\n",
    "\n",
    "    # Wide to long form transformation\n",
    "    data = data.melt(id_vars=['iso3','Province/State','Country/Region','Lat','Long','Population'])\n",
    "    data.rename(columns={'variable':'Date','value':type},inplace=True)\n",
    "    # data['Date'] = pd.to_datetime(data['Date'],format='%m/%d/%y')\n",
    "    data[type].fillna(0,inplace=True)\n",
    "    data['Province/State'].replace(np.nan,'NA',inplace=True)\n",
    "    \n",
    "    # Reorder columns\n",
    "    data = data[[data.columns[-2]]+list(data.columns[:-2])+[data.columns[-1]]]\n",
    "\n",
    "    # per 100K (r_: Rate)\n",
    "    data['r_'+type] = data[type]/data['Population']*base_pop\n",
    "\n",
    "    # Daily changes (i_: Daily Raw, ri_: Daily Rate)\n",
    "    data['i_'+type] = data[type]-data.groupby(['iso3','Province/State','Country/Region'])[type].shift(1)\n",
    "    data['i_'+type].fillna(data[type],inplace=True)\n",
    "    # print(data[['Date','Country/Region','Province/State',type,'i_'+type]])\n",
    "    # print(data)\n",
    "    data['ri_'+type] = data['i_'+type]/data['Population']*base_pop\n",
    "    # data['ri'+type].fillna(data['r'+type],inplace=True)\n",
    "\n",
    "    # Country-level grouping\n",
    "    data['Tot_'+type] = data.groupby(['Date','iso3','Country/Region'])[type].transform('sum')\n",
    "\n",
    "    data['iTot_'+type] = data.groupby(['Date','iso3','Country/Region'])['i_'+type].transform('sum')\n",
    "    data['rTot_'+type] = data['Tot_'+type]/data.groupby(['Date','iso3','Country/Region'])['Population'].transform('sum')*base_pop\n",
    "    data['riTot_'+type] = data['iTot_'+type]/data.groupby(['Date','iso3','Country/Region'])['Population'].transform('sum')*base_pop\n",
    "\n",
    "    # print(data[['Date','Country/Region','Province/State',type,'i_'+type]])\n",
    "\n",
    "    data.drop(data[data['Date']==data['Date'][0]].index,inplace=True)\n",
    "    data = data.round(4)\n",
    "    data.reset_index(drop=True,inplace=True)\n",
    "#     print(data[['Date','Country/Region','Province/State',type,'i_'+type]])\n",
    "\n",
    "#     print(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50aabf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(data,type,date,target_path=target_path):\n",
    "    filename = 'csse_covid_19_time_series/'+target_path['summary']\n",
    "    print('{}: {}'.format(type,filename))\n",
    "    data.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ede4a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_appendfile():\n",
    "#     # Read current file\n",
    "#     file_list = target_path['summary']\n",
    "\n",
    "#     read_columns = ['Date','iso3','Province/State','Country/Region','Lat','Long',\\\n",
    "#                     'Population','Confirmed','r_Confirmed','i_Confirmed','ri_Confirmed',\\\n",
    "#                     'Tot_Confirmed','iTot_Confirmed','rTot_Confirmed','riTot_Confirmed',\\\n",
    "#                     'Deaths','r_Deaths','i_Deaths','ri_Deaths','Tot_Deaths','iTot_Deaths',\\\n",
    "#                     'rTot_Deaths','riTot_Deaths']\n",
    "\n",
    "#     try:\n",
    "#         print(\"Reading previous summary data with the filename: \"+file_list)\n",
    "#         last = pd.read_csv(\"data/\"+target_path['summary'])\n",
    "#         new = last.copy()\n",
    "#         if len(read_columns) == len(last.columns):\n",
    "#             status = 'Replace'\n",
    "#         else:\n",
    "#             status = \"New\"\n",
    "\n",
    "#     except FileNotFoundError:\n",
    "#         print('Current summary file not found\\nNo backup file(s) will be created')\n",
    "#         status = \"New\"\n",
    "\n",
    "\n",
    "#     ds = read_source()\n",
    "#     start_date = get_startdate(ds)\n",
    "#     new = ds\n",
    "\n",
    "#     # else:\n",
    "#     #     # ds = read_source(start_date)\n",
    "#     #     new.drop(new.loc[new['Date']>=start_date,:].index,inplace=True)\n",
    "\n",
    "#     write_date = datetime.strptime(ds.iloc[-1]['Date'],'%m/%d/%y').strftime('%m-%d-%Y')\n",
    "\n",
    "#     # Write to files\n",
    "#     print(\"Updating summary data: {}\".format(status))\n",
    "#     if status == 'Replace':\n",
    "#         write_file(last,'last',write_date)\n",
    "#         write_file(new,'new',write_date)\n",
    "#         write_file(new,'remote',write_date)\n",
    "#     else:\n",
    "#         write_file(new,'new',write_date)\n",
    "#         write_file(new,'remote',write_date)\n",
    "#     print(\"Summary data successfully updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c0e81c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-09\n",
      "2022-04-14\n",
      "new: csse_covid_19_time_series/time_series_covid19.csv\n",
      "Summary data successfully updated\n"
     ]
    }
   ],
   "source": [
    "read_appendfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfefce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid = pd.read_csv('csse_covid_19_time_series/time_series_covid19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfa3f814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>iso3</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Population</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>r_Confirmed</th>\n",
       "      <th>i_Confirmed</th>\n",
       "      <th>...</th>\n",
       "      <th>rTot_Confirmed</th>\n",
       "      <th>riTot_Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>r_Deaths</th>\n",
       "      <th>i_Deaths</th>\n",
       "      <th>ri_Deaths</th>\n",
       "      <th>Tot_Deaths</th>\n",
       "      <th>iTot_Deaths</th>\n",
       "      <th>rTot_Deaths</th>\n",
       "      <th>riTot_Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.9391</td>\n",
       "      <td>67.7100</td>\n",
       "      <td>38928341.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>ALB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.1533</td>\n",
       "      <td>20.1683</td>\n",
       "      <td>2877800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>DZA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.0339</td>\n",
       "      <td>1.6596</td>\n",
       "      <td>43851043.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>AND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.5063</td>\n",
       "      <td>1.5218</td>\n",
       "      <td>77265.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>AGO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.2027</td>\n",
       "      <td>17.8739</td>\n",
       "      <td>32866268.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date iso3 Province/State Country/Region      Lat     Long  Population  \\\n",
       "0  1/23/20  AFG            NaN    Afghanistan  33.9391  67.7100  38928341.0   \n",
       "1  1/23/20  ALB            NaN        Albania  41.1533  20.1683   2877800.0   \n",
       "2  1/23/20  DZA            NaN        Algeria  28.0339   1.6596  43851043.0   \n",
       "3  1/23/20  AND            NaN        Andorra  42.5063   1.5218     77265.0   \n",
       "4  1/23/20  AGO            NaN         Angola -11.2027  17.8739  32866268.0   \n",
       "\n",
       "   Confirmed  r_Confirmed  i_Confirmed  ...  rTot_Confirmed  riTot_Confirmed  \\\n",
       "0          0          0.0          0.0  ...             0.0              0.0   \n",
       "1          0          0.0          0.0  ...             0.0              0.0   \n",
       "2          0          0.0          0.0  ...             0.0              0.0   \n",
       "3          0          0.0          0.0  ...             0.0              0.0   \n",
       "4          0          0.0          0.0  ...             0.0              0.0   \n",
       "\n",
       "   Deaths  r_Deaths  i_Deaths  ri_Deaths  Tot_Deaths  iTot_Deaths  \\\n",
       "0       0       0.0       0.0        0.0           0          0.0   \n",
       "1       0       0.0       0.0        0.0           0          0.0   \n",
       "2       0       0.0       0.0        0.0           0          0.0   \n",
       "3       0       0.0       0.0        0.0           0          0.0   \n",
       "4       0       0.0       0.0        0.0           0          0.0   \n",
       "\n",
       "   rTot_Deaths  riTot_Deaths  \n",
       "0          0.0           0.0  \n",
       "1          0.0           0.0  \n",
       "2          0.0           0.0  \n",
       "3          0.0           0.0  \n",
       "4          0.0           0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6112d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid['Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c338c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f88e88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81091509",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/web-data/data/cases_country.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_states_df = covid[covid['adm0_a3']=='USA'].groupby(''.sort_values('Confirmed', ascending= False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7015239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_confirmed_df = pd.read_csv('csse_covid_19_time_series/time_series_covid19_confirmed_us.csv')\n",
    "us_deaths_df = pd.read_csv('csse_covid_19_time_series/time_series_covid19_deaths_us.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a64f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_per_state = us_confirmed_df.groupby(['Province_State']).sum().drop(['UID', 'code3', 'FIPS', 'Lat', 'Long_'], axis=1).reset_index().sort_values(by='4/7/22', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f80766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287971c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_per_state.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d593e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_per_state = us_deaths_df.groupby(['Province_State']).sum().drop(['UID', 'code3', 'FIPS', 'Lat', 'Long_'], axis=1).reset_index().sort_values(by='4/7/22', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b78c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_per_state['rate'] = ((deaths_per_state['4/7/22']/deaths_per_state['Population'])*100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856e570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_per_state.sort_values(by = 'rate', ascending=False).iloc[1:,:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e4d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_per_state.sort_values(by = '4/7/22', ascending=False).iloc[:,:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf5c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/web-data/data/cases_country.csv')\n",
    "sorted_country_df = country_df[country_df['Confirmed'] > 0].sort_values('Confirmed', ascending= True)\n",
    "sorted_country_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e5361",
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_per_state['Confirmed'] = confirmed_per_state['4/7/22']\n",
    "confirmed_per_state.sort_values('Confirmed', ascending= False)\n",
    "confirmed_per_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d4a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_per_state = us_deaths_df.groupby(['Province_State']).sum().drop(['UID', 'code3', 'FIPS', 'Lat', 'Long_'], axis=1).reset_index().sort_values(by='4/7/22', ascending=False)\n",
    "deaths_per_state['Deaths'] = deaths_per_state['4/7/22']\n",
    "deaths_per_state.sort_values('Deaths', ascending= False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59263f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_per_state['Fatality_rate'] = (deaths_per_state['4/7/22']/deaths_per_state['Population'])*100\n",
    "deaths_per_state = deaths_per_state.sort_values('Fatality_rate', ascending= False).iloc[1:]\n",
    "deaths_per_state.sort_values('Fatality_rate', ascending= False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68817dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_confirmed_df = pd.read_csv('csse_covid_19_time_series/time_series_covid19_confirmed_us.csv')\n",
    "us_deaths_df = pd.read_csv('csse_covid_19_time_series/time_series_covid19_deaths_us.csv')\n",
    "\n",
    "\n",
    "confirmed_per_state = us_confirmed_df.groupby(['Province_State']).sum().drop(['UID', 'code3', 'FIPS', 'Lat', 'Long_'], axis=1).reset_index().sort_values(by='4/7/22', ascending=False)\n",
    "confirmed_per_state['Confirmed'] = confirmed_per_state['4/7/22']\n",
    "\n",
    "deaths_per_state = us_deaths_df.groupby(['Province_State']).sum().drop(['UID', 'code3', 'FIPS', 'Lat', 'Long_'], axis=1).reset_index().sort_values(by='4/7/22', ascending=False)\n",
    "deaths_per_state = deaths_per_state[deaths_per_state['Population']>0]\n",
    "deaths_per_state['Deaths'] = deaths_per_state['4/7/22']\n",
    "deaths_per_state['Fatality_rate'] = (deaths_per_state['4/7/22']/deaths_per_state['Population'])*100\n",
    "\n",
    "df = pd.merge(confirmed_per_state[{'Province_State', 'Confirmed'}],\\\n",
    "         deaths_per_state[{'Province_State', 'Deaths', 'Fatality_rate'}], on='Province_State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e0f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Fatality_rate', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e152d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_per_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39552e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781d84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c529a725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
